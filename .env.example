# HuggingFace token for accessing FLUX.1-Kontext-dev model
HF_TOKEN=your_huggingface_token_here

# Server configuration
HOST=0.0.0.0
PORT=8000

# GPU settings (optional)
CUDA_VISIBLE_DEVICES=0

# Memory optimization (optional)
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512,garbage_collection_threshold:0.9

# Disable profiling if you encounter issues (optional)
DISABLE_PROFILING=false

# Cache directory (optional, defaults to ~/.cache/flux_optimized)
FLUX_CACHE_DIR=

# Model specific settings (optional)
FLUX_MODEL_ID=black-forest-labs/FLUX.1-Kontext-dev
FLUX_DTYPE=bfloat16

# Optimization toggles (optional)
ENABLE_FLASH_ATTENTION=false
ENABLE_MXFP4=true
ENABLE_TENSORRT=false
ENABLE_PARA_ATTENTION=false

# Scheduler type (optional): dpm_solver or euler
SCHEDULER_TYPE=dpm_solver